{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/rodrigozago/compiladores/blob/master/Lexico.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hh9K9qYJ9t23"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y2vT3_Y0DbZR"
   },
   "source": [
    "Analisador léxico\n",
    "=================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sOwtiPdOC3mm"
   },
   "source": [
    "Definição da tabela de simbolos\n",
    "--------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wLc-ORg8omQA"
   },
   "source": [
    "Classe que define a tabela de simbolos.\n",
    "\n",
    "symTable: Estrutura do tipo dict para armazenar os tokens:\n",
    "\n",
    "```{ lexema<string> : token<Token> }```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "id": "stf4cugLAO69"
   },
   "outputs": [],
   "source": [
    "class SymTable:\n",
    "    def __init__(self):\n",
    "        self.symTable = dict();\n",
    "    def addNewEntry(self, token):\n",
    "        if(token.lexema not in self.symTable):\n",
    "            self.symTable[token.lexema] = token\n",
    "        return token\n",
    "    def getEntry(self, lexema):\n",
    "        if(lexema in self.symTable):\n",
    "            return self.symTable[lexema]\n",
    "        else:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nuVejW89C-QD"
   },
   "source": [
    "Definição da classe Token\n",
    "--------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "id": "9532H6Ww13I-"
   },
   "outputs": [],
   "source": [
    "class Token:\n",
    "  def __init__(self, lexema, token, tipo):\n",
    "    self.lexema = lexema\n",
    "    self.token = token\n",
    "    self.tipo = tipo\n",
    "\n",
    "  def __str__(self):\n",
    "    return \"Lexema: {} Token: {} Tipo: {}\".format(self.lexema, self.token, self.tipo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hygyYiRGDLif"
   },
   "source": [
    "Adicionando palavras chave da linguagem na tabela de simbolos\n",
    "---------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "id": "aJtF1gCt2UcV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debug: adicionando\n",
      "debug: adicionando\n",
      "debug: adicionando\n",
      "debug: adicionando\n",
      "debug: adicionando\n",
      "debug: adicionando\n",
      "debug: adicionando\n",
      "debug: adicionando\n",
      "debug: adicionando\n",
      "debug: adicionando\n",
      "debug: adicionando\n",
      "debug: adicionando\n"
     ]
    }
   ],
   "source": [
    "# Creating symbol table\n",
    "table = SymTable()\n",
    "\n",
    "# Add keywords into symbol table\n",
    "try:\n",
    "    table.addNewEntry(Token('inicio', 'inicio', '-'))\n",
    "    table.addNewEntry(Token('varinicio', 'varinicio', '-'))\n",
    "    table.addNewEntry(Token('varfim', 'varfim', '-'))\n",
    "    table.addNewEntry(Token('escreva', 'escreva', '-'))\n",
    "    table.addNewEntry(Token('leia', 'leia', '-'))\n",
    "    table.addNewEntry(Token('se', 'se', '-'))\n",
    "    table.addNewEntry(Token('entao', 'entao', '-'))\n",
    "    table.addNewEntry(Token('fimse', 'fimse', '-'))\n",
    "    table.addNewEntry(Token('fim', 'fim', '-'))\n",
    "    table.addNewEntry(Token('inteiro', 'inteiro', '-'))\n",
    "    table.addNewEntry(Token('lit', 'lit', '-'))\n",
    "    table.addNewEntry(Token('real', 'real', '-'))    \n",
    "except Exception as e:\n",
    "    print(\"erro: {}\".format(e))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "3vi1Dc_uB72u",
    "outputId": "6f8c754c-d0d1-468a-9dd6-3a45fe445268"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lexema: inicio Token: inicio Tipo: -\n"
     ]
    }
   ],
   "source": [
    "print(table.addNewEntry(Token('inicio', 'inicio', '-')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lexema: inicio Token: inicio Tipo: -\n"
     ]
    }
   ],
   "source": [
    "print(table.symTable['inicio'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tabela dos estados finais\n",
    "-------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_tokens = {\n",
    "    1: 'Num',\n",
    "    2: 'Num',\n",
    "    3: 'Num',\n",
    "    6: 'Num',\n",
    "    8: 'Literal',\n",
    "    9: 'id',\n",
    "    11: 'Comentário',\n",
    "    12: 'EOF',\n",
    "    13: 'OPR',\n",
    "    14: 'OPR',\n",
    "    15: 'OPR',\n",
    "    16: 'OPR',\n",
    "    17: 'RCB',\n",
    "    18: 'OPR',\n",
    "    19: 'OPM',\n",
    "    20: 'AB_P',\n",
    "    21: 'FC_P',\n",
    "    22: 'PTV'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zNsCQ-6iomQK"
   },
   "source": [
    "Definição do autômato finito\n",
    "-----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definicao da class DFA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "id": "4bZOZet-Dqv6"
   },
   "outputs": [],
   "source": [
    "class DFA:\n",
    "    current_state = None;\n",
    "    def __init__(self, states, alphabet, transition_function, start_state, accept_states):\n",
    "        self.states = states;\n",
    "        self.alphabet = alphabet;\n",
    "        self.transition_function = transition_function;\n",
    "        self.start_state = start_state;\n",
    "        self.accept_states = accept_states;\n",
    "        self.current_state = start_state;\n",
    "        return;\n",
    "    \n",
    "    def transition_to_state_with_input(self, input_value):\n",
    "        if((self.current_state, input_value) not in self.transition_function.keys()):\n",
    "            \n",
    "            if((self.current_state, '@') in self.transition_function.keys()):\n",
    "                \n",
    "                self.current_state = self.transition_function[(self.current_state, '@')];\n",
    "                return True;\n",
    "            \n",
    "            return False;\n",
    "        \n",
    "        previous_state = self.current_state;\n",
    "        self.current_state = self.transition_function[(self.current_state, input_value)];\n",
    "        \n",
    "        print(\"({}, {}) -> {}\".format(previous_state, input_value, self.current_state))\n",
    "        \n",
    "        return True;\n",
    "    \n",
    "    def analisys(self, input_list):\n",
    "        self.go_to_initial_state();\n",
    "        tokens = []\n",
    "        lexema = \"\"\n",
    "        last_accept_state = None\n",
    "        i = 0\n",
    "\n",
    "        while i < len(input_list): \n",
    "            thisState = self.current_state\n",
    "            didTransition = self.transition_to_state_with_input(input_list[i]);\n",
    "            \n",
    "            if(self.current_state is 23):\n",
    "                i = i + 1\n",
    "                self.go_to_initial_state()\n",
    "                lexema = \"\"\n",
    "                continue\n",
    "            \n",
    "            if didTransition:\n",
    "                lexema = lexema + input_list[i]\n",
    "                last_accept_state = self.current_state\n",
    "                if i is len(input_list)-1:\n",
    "                    token = Token(lexema, state_tokens[self.current_state], '-')\n",
    "                    print(token)\n",
    "                    tokens.append(token)\n",
    "                    self.go_to_initial_state()\n",
    "                    lexema = \"\"\n",
    "            else:\n",
    "                if self.in_accept_state():\n",
    "                    token = Token(lexema, state_tokens[self.current_state], '-')\n",
    "                    token = self.addToSymbolTable(lexema, token)\n",
    "                    print(token)\n",
    "                    tokens.append(token)\n",
    "                    self.go_to_initial_state()\n",
    "                    lexema = \"\"\n",
    "                    continue\n",
    "                else: \n",
    "                    print(\"Erro em: ({}, {}) -> {}\".format('?', input_list[i], self.current_state))\n",
    "                    lexema = \"\"\n",
    "                    self.go_to_initial_state()\n",
    "                    \n",
    "            i = i + 1\n",
    "            \n",
    "            \n",
    "    def addToSymbolTable(self, lexema, token):\n",
    "        result = table.getEntry(lexema)\n",
    "        if result:\n",
    "            return result\n",
    "        else: \n",
    "            return table.addNewEntry(token)\n",
    "        \n",
    "    \n",
    "    def in_accept_state(self):\n",
    "        return self.current_state in accept_states;\n",
    "    \n",
    "    def go_to_initial_state(self):\n",
    "        self.current_state = self.start_state;\n",
    "        return;\n",
    "    \n",
    "    def run_with_input_list(self, input_list):\n",
    "        self.go_to_initial_state();\n",
    "        for inp in input_list:\n",
    "            self.transition_to_state_with_input(inp);\n",
    "            continue;\n",
    "        return self.in_accept_state();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eT6Ud-XkomQL"
   },
   "source": [
    "Definindo função de transição"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "id": "ZhuDqr5VomQL"
   },
   "outputs": [],
   "source": [
    "tf = dict();\n",
    "\n",
    "# Ignore tab, \\n, and spaces\n",
    "# tf[(0, ' ')] = 0;\n",
    "# tf[(0, '\\n')] = 0;\n",
    "# tf[(0, '\\t')] = 0;\n",
    "\n",
    "tf[(0, ' ')] = 23;\n",
    "tf[(0, '\\n')] = 23;\n",
    "tf[(0, '\\t')] = 23;\n",
    "\n",
    "# Begin tf[(0, D)] = 1;\n",
    "tf[(0, '0')] = 1;\n",
    "tf[(0, '1')] = 1;\n",
    "tf[(0, '2')] = 1;\n",
    "tf[(0, '3')] = 1;\n",
    "tf[(0, '4')] = 1;\n",
    "tf[(0, '5')] = 1;\n",
    "tf[(0, '6')] = 1;\n",
    "tf[(0, '7')] = 1;\n",
    "tf[(0, '8')] = 1;\n",
    "tf[(0, '9')] = 1;\n",
    "# End tf[(0, D)] = 1;\n",
    "\n",
    "# Begin tf[(1, D)] = 1;\n",
    "tf[(1, '0')] = 1;\n",
    "tf[(1, '1')] = 1;\n",
    "tf[(1, '2')] = 1;\n",
    "tf[(1, '3')] = 1;\n",
    "tf[(1, '4')] = 1;\n",
    "tf[(1, '5')] = 1;\n",
    "tf[(1, '6')] = 1;\n",
    "tf[(1, '7')] = 1;\n",
    "tf[(1, '8')] = 1;\n",
    "tf[(1, '9')] = 1;\n",
    "# End tf[(1, D)] = 1;\n",
    "\n",
    "#TODO RESOLVER \\. \n",
    "tf[(1, '.')] = 2;\n",
    "tf[(1, 'E')] = 4;\n",
    "tf[(1, 'e')] = 4;\n",
    "\n",
    "# Begin tf[(2, D)] = 3;\n",
    "tf[(2, '0')] = 3;\n",
    "tf[(2, '1')] = 3;\n",
    "tf[(2, '2')] = 3;\n",
    "tf[(2, '3')] = 3;\n",
    "tf[(2, '4')] = 3;\n",
    "tf[(2, '5')] = 3;\n",
    "tf[(2, '6')] = 3;\n",
    "tf[(2, '7')] = 3;\n",
    "tf[(2, '8')] = 3;\n",
    "tf[(2, '9')] = 3;\n",
    "# End tf[(2, D)] = 3;\n",
    "\n",
    "# TODO VERIFICAR COM O PRATES\n",
    "# tf[(2, \"QUALQUER COISA\")] = 23;\n",
    "\n",
    "# Begin tf[(3, D)] = 3;\n",
    "tf[(3, '0')] = 3;\n",
    "tf[(3, '1')] = 3;\n",
    "tf[(3, '2')] = 3;\n",
    "tf[(3, '3')] = 3;\n",
    "tf[(3, '4')] = 3;\n",
    "tf[(3, '5')] = 3;\n",
    "tf[(3, '6')] = 3;\n",
    "tf[(3, '7')] = 3;\n",
    "tf[(3, '8')] = 3;\n",
    "tf[(3, '9')] = 3;\n",
    "# End tf[(3, D)] = 3;\n",
    "\n",
    "tf[(3, 'E')] = 4;\n",
    "tf[(3, 'e')] = 4;\n",
    "tf[(4, '+')] = 5;\n",
    "tf[(4, '-')] = 5;\n",
    "\n",
    "# Begin tf[(4, D)] = 6;\n",
    "tf[(4, '0')] = 6;\n",
    "tf[(4, '1')] = 6;\n",
    "tf[(4, '2')] = 6;\n",
    "tf[(4, '3')] = 6;\n",
    "tf[(4, '4')] = 6;\n",
    "tf[(4, '5')] = 6;\n",
    "tf[(4, '6')] = 6;\n",
    "tf[(4, '7')] = 6;\n",
    "tf[(4, '8')] = 6;\n",
    "tf[(4, '9')] = 6;\n",
    "# End tf[(4, D)] = 6;\n",
    "\n",
    "# TODO VERIFICAR COM O PRATES (ACONTECEU ERRO?)\n",
    "# tf[(4, 'QUALQUER COISA')] = 23;\n",
    "\n",
    "# Begin tf[(5, D)] = 6;\n",
    "tf[(5, '0')] = 6;\n",
    "tf[(5, '1')] = 6;\n",
    "tf[(5, '2')] = 6;\n",
    "tf[(5, '3')] = 6;\n",
    "tf[(5, '4')] = 6;\n",
    "tf[(5, '5')] = 6;\n",
    "tf[(5, '6')] = 6;\n",
    "tf[(5, '7')] = 6;\n",
    "tf[(5, '8')] = 6;\n",
    "tf[(5, '9')] = 6;\n",
    "# End tf[(5, D)] = 6;\n",
    "\n",
    "# TODO VERIFICAR COM O PRATES (ACONTECEU ERRO?)\n",
    "# tf[(5, 'QUALQUER COISA')] = 23;\n",
    "\n",
    "# Begin tf[(6, D)] = 6;\n",
    "tf[(6, '0')] = 6;\n",
    "tf[(6, '1')] = 6;\n",
    "tf[(6, '2')] = 6;\n",
    "tf[(6, '3')] = 6;\n",
    "tf[(6, '4')] = 6;\n",
    "tf[(6, '5')] = 6;\n",
    "tf[(6, '6')] = 6;\n",
    "tf[(6, '7')] = 6;\n",
    "tf[(6, '8')] = 6;\n",
    "tf[(6, '9')] = 6;\n",
    "# End tf[(6, D)] = 6;\n",
    "\n",
    "tf[(0, '\"')] = 7;\n",
    "tf[(7, '@')] = 7; # aqui o @ substitui ., aceita tudo \n",
    "tf[(7, '\"')] = 8;\n",
    "\n",
    "# Begin tf[(0, L)] = 9;\n",
    "tf[(0, 'a')] = 9;\n",
    "tf[(0, 'b')] = 9;\n",
    "tf[(0, 'c')] = 9;\n",
    "tf[(0, 'd')] = 9;\n",
    "tf[(0, 'e')] = 9;\n",
    "tf[(0, 'f')] = 9;\n",
    "tf[(0, 'g')] = 9;\n",
    "tf[(0, 'h')] = 9;\n",
    "tf[(0, 'i')] = 9;\n",
    "tf[(0, 'j')] = 9;\n",
    "tf[(0, 'k')] = 9;\n",
    "tf[(0, 'l')] = 9;\n",
    "tf[(0, 'm')] = 9;\n",
    "tf[(0, 'n')] = 9;\n",
    "tf[(0, 'o')] = 9;\n",
    "tf[(0, 'p')] = 9;\n",
    "tf[(0, 'q')] = 9;\n",
    "tf[(0, 'r')] = 9;\n",
    "tf[(0, 's')] = 9;\n",
    "tf[(0, 't')] = 9;\n",
    "tf[(0, 'u')] = 9;\n",
    "tf[(0, 'v')] = 9;\n",
    "tf[(0, 'w')] = 9;\n",
    "tf[(0, 'x')] = 9;\n",
    "tf[(0, 'y')] = 9;\n",
    "tf[(0, 'z')] = 9;\n",
    "tf[(0, 'A')] = 9;\n",
    "tf[(0, 'B')] = 9;\n",
    "tf[(0, 'C')] = 9;\n",
    "tf[(0, 'D')] = 9;\n",
    "tf[(0, 'E')] = 9;\n",
    "tf[(0, 'F')] = 9;\n",
    "tf[(0, 'G')] = 9;\n",
    "tf[(0, 'H')] = 9;\n",
    "tf[(0, 'I')] = 9;\n",
    "tf[(0, 'J')] = 9;\n",
    "tf[(0, 'K')] = 9;\n",
    "tf[(0, 'L')] = 9;\n",
    "tf[(0, 'M')] = 9;\n",
    "tf[(0, 'N')] = 9;\n",
    "tf[(0, 'O')] = 9;\n",
    "tf[(0, 'P')] = 9;\n",
    "tf[(0, 'Q')] = 9;\n",
    "tf[(0, 'R')] = 9;\n",
    "tf[(0, 'S')] = 9;\n",
    "tf[(0, 'T')] = 9;\n",
    "tf[(0, 'U')] = 9;\n",
    "tf[(0, 'V')] = 9;\n",
    "tf[(0, 'W')] = 9;\n",
    "tf[(0, 'X')] = 9;\n",
    "tf[(0, 'Y')] = 9;\n",
    "tf[(0, 'Z')] = 9;\n",
    "# End tf[(0, L)] = 9;\n",
    "\n",
    "# Begin tf[(9, L)] = 9;\n",
    "tf[(9, 'a')] = 9;\n",
    "tf[(9, 'b')] = 9;\n",
    "tf[(9, 'c')] = 9;\n",
    "tf[(9, 'd')] = 9;\n",
    "tf[(9, 'e')] = 9;\n",
    "tf[(9, 'f')] = 9;\n",
    "tf[(9, 'g')] = 9;\n",
    "tf[(9, 'h')] = 9;\n",
    "tf[(9, 'i')] = 9;\n",
    "tf[(9, 'j')] = 9;\n",
    "tf[(9, 'k')] = 9;\n",
    "tf[(9, 'l')] = 9;\n",
    "tf[(9, 'm')] = 9;\n",
    "tf[(9, 'n')] = 9;\n",
    "tf[(9, 'o')] = 9;\n",
    "tf[(9, 'p')] = 9;\n",
    "tf[(9, 'q')] = 9;\n",
    "tf[(9, 'r')] = 9;\n",
    "tf[(9, 's')] = 9;\n",
    "tf[(9, 't')] = 9;\n",
    "tf[(9, 'u')] = 9;\n",
    "tf[(9, 'v')] = 9;\n",
    "tf[(9, 'w')] = 9;\n",
    "tf[(9, 'x')] = 9;\n",
    "tf[(9, 'y')] = 9;\n",
    "tf[(9, 'z')] = 9;\n",
    "tf[(9, 'A')] = 9;\n",
    "tf[(9, 'B')] = 9;\n",
    "tf[(9, 'C')] = 9;\n",
    "tf[(9, 'D')] = 9;\n",
    "tf[(9, 'E')] = 9;\n",
    "tf[(9, 'F')] = 9;\n",
    "tf[(9, 'G')] = 9;\n",
    "tf[(9, 'H')] = 9;\n",
    "tf[(9, 'I')] = 9;\n",
    "tf[(9, 'J')] = 9;\n",
    "tf[(9, 'K')] = 9;\n",
    "tf[(9, 'L')] = 9;\n",
    "tf[(9, 'M')] = 9;\n",
    "tf[(9, 'N')] = 9;\n",
    "tf[(9, 'O')] = 9;\n",
    "tf[(9, 'P')] = 9;\n",
    "tf[(9, 'Q')] = 9;\n",
    "tf[(9, 'R')] = 9;\n",
    "tf[(9, 'S')] = 9;\n",
    "tf[(9, 'T')] = 9;\n",
    "tf[(9, 'U')] = 9;\n",
    "tf[(9, 'V')] = 9;\n",
    "tf[(9, 'W')] = 9;\n",
    "tf[(9, 'X')] = 9;\n",
    "tf[(9, 'Y')] = 9;\n",
    "tf[(9, 'Z')] = 9;\n",
    "# End tf[(9, L)] = 9;\n",
    "\n",
    "\n",
    "\n",
    "# Begin tf[(9, D)] = 9;\n",
    "tf[(9, '0')] = 9;\n",
    "tf[(9, '1')] = 9;\n",
    "tf[(9, '2')] = 9;\n",
    "tf[(9, '3')] = 9;\n",
    "tf[(9, '4')] = 9;\n",
    "tf[(9, '5')] = 9;\n",
    "tf[(9, '6')] = 9;\n",
    "tf[(9, '7')] = 9;\n",
    "tf[(9, '8')] = 9;\n",
    "tf[(9, '9')] = 9;\n",
    "# End tf[(9, D)] = 9;\n",
    "\n",
    "tf[(9, '_')] = 9;\n",
    "\n",
    "\n",
    "tf[(0, '{')] = 10;\n",
    "tf[(10, '@')] = 10; # aqui o @ substitui ., aceita tudo \n",
    "tf[(10, '}')] = 11;\n",
    "\n",
    "\n",
    "tf[(0, '$')] = 12;\n",
    "\n",
    "tf[(0, '>')] = 13;\n",
    "tf[(13, '=')] = 14;\n",
    "\n",
    "tf[(0, '<')] = 15;\n",
    "tf[(15, '=')] = 14;\n",
    "tf[(15, '>')] = 16;\n",
    "tf[(15, '-')] = 17;\n",
    "\n",
    "tf[(0, '=')] = 18;\n",
    "\n",
    "# Begin tf[(0, OP)] = 19;\n",
    "tf[(0, '+')] = 19;\n",
    "tf[(0, '-')] = 19;\n",
    "tf[(0, '*')] = 19;\n",
    "tf[(0, '/')] = 19;\n",
    "# End tf[(0, OP)] = 19;\n",
    "\n",
    "tf[(0, '(')] = 20;\n",
    "tf[(0, ')')] = 21;\n",
    "tf[(0, ';')] = 22;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definicao do alfabeto e estados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23};\n",
    "alphabet = {\n",
    "    'a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','y','x','z', \n",
    "    'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'R', 'S', 'T', 'U', 'V', 'W', 'Y', 'X', 'Z',\n",
    "    '0','1','2','3','4','5','6','7','8','9', \n",
    "    '+','-','*','/', \n",
    "    ' ','{','}','\"',';','(',')','.', '>','<','='};\n",
    "start_state = 0;\n",
    "accept_states = {1, 3, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23};"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicializacao do automato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = DFA(states, alphabet, tf, start_state, accept_states);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teste do automato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'list' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-112-2936778921c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minp_program\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalisys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp_program\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'list' object is not callable"
     ]
    }
   ],
   "source": [
    "inp_program = list(\"\\n\");\n",
    "\n",
    "d.analisys(inp_program);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_u6FDOygDjs9"
   },
   "source": [
    "Definição do Analisador Léxico\n",
    "----------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7ox1q3FWomQQ"
   },
   "outputs": [],
   "source": [
    "class Scanner:\n",
    "    dfa = None\n",
    "    file = None\n",
    "    rowList = None\n",
    "    def __init__(self):    \n",
    "        self.file = open('fonte.alg')\n",
    "        self.rowList = list(self.file)\n",
    "    def doAnalisys(self):\n",
    "        for i, row in enumerate(self.rowList):\n",
    "            charList = list(row)\n",
    "            for j, char in enumerate(charList):\n",
    "                print(\"Caracter: {} Linha: {} Coluna: {}\".format(char, i, j))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "list = Scanner().rowList "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\t\\tB inteiro;\\n'"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, \t) -> 23\n",
      "(0, \t) -> 23\n",
      "(0, B) -> 9\n",
      "debug: adicionando\n",
      "Lexema: B Token: id Tipo: -\n",
      "(0,  ) -> 23\n",
      "(0, i) -> 9\n",
      "(9, n) -> 9\n",
      "(9, t) -> 9\n",
      "(9, e) -> 9\n",
      "(9, i) -> 9\n",
      "(9, r) -> 9\n",
      "(9, o) -> 9\n",
      "Lexema: inteiro Token: inteiro Tipo: -\n",
      "(0, ;) -> 22\n",
      "Lexema: ; Token: PTV Tipo: -\n",
      "(0, \n",
      ") -> 23\n"
     ]
    }
   ],
   "source": [
    "d.analisys(list[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "x = re.match(r'\\n|\\t','\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(0, 1), match='\\n'>\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "is in transition function\n"
     ]
    }
   ],
   "source": [
    "a = dict();\n",
    "\n",
    "# Ignore tab, \\n, and spaces\n",
    "a[(0, ' ')] = 0;\n",
    "a[(0, '\\n')] = 1;\n",
    "a[(0, '\\t')] = 0;\n",
    "\n",
    "if((0, \"\\n\") in a.keys()):\n",
    "    print(a[(0, \"\\n\")])\n",
    "    print('is in transition function')\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "sOwtiPdOC3mm",
    "nuVejW89C-QD"
   ],
   "include_colab_link": true,
   "name": "Lexico.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
